---
layout: page
title: Machine Learning
---
	<h2>Linear Regression, Ridge Regression, Lasso Regression</h2>
	<h6>July 2020</h6><br/>
	<p>In this project, three different types of linear regression methods are performed: plain linear regression with no regularization, ridge regression with regularization, and lasso regression. After the models were trained, their performances were quantitatively analyzed by the MSE values on the validation datasets.</p>
	<img src="images/Lasso plot.png", width="200">
	<ul class="actions">
	<li><a href="files/Linear Regression, Ridge Regression, Lasso Regression.pdf" target="_blank" class="button special icon fa-download">Report</a></li>
	</ul>
	<hr />

	<h2>Logistic Regression</h2>
	<h6>July 2020</h6><br/>
	<p>In this project, a binary classification dataset was chosen and logistic regression with stochastic gradient descent(SGA) as the optimization algorithm was implemented. SGD without regularization and SGD with regularization are implemented, and their performances were analyzed based on % correct on the test dataset. Lastly, likelihood functions with respect to iterations for unregularized and regularized logistic regression are plotted and compared.</p>
	<img src="images/Step size.png">
	<img src="images/Log likelihood.png">
	<ul class="actions">
	<li><a href="files/Logistic Regression.pdf" target="_blank" class="button special icon fa-download">Report</a></li>
	</ul>
	<hr />

	<h2>Model Assessment and Selection</h2>
	<h6>July 2020</h6><br/>
	<p>In this project, a right way and a wrong way of applying a K-fold cross validation(CV) as a method of model assessment is analyzed. In the wrong way of applying K-fold CV, feature selection is implemented before the dataset is split into K folds; on the other hand, in the right way of applying K-fold CV, splitting dataset into K folds is followed by the feature selection of each fold.</p>
	<ul class="actions">
	<li><a href="files/Model Assessment and Selection.pdf" target="_blank" class="button special icon fa-download">Report</a></li>
	</ul>
	<hr />

	<h2>eXtreme Gradient Boosted Trees</h2>
	<h6>July 2020</h6><br/>
	<p>In this project, eXtreme gradient boosted trees algorithm is used to train the model. Among several parameters that can be manually chosen(eta, gamma, lambda, alpha, max_depth and more), only lambda is optimized in this project for simplicity.</p>
	<img src="images/Feature importance XGB.png">
	<ul class="actions">
	<li><a href="files/eXtreme Gradient Boosted Trees.pdf" target="_blank" class="button special icon fa-download">Report</a></li>
	</ul>
	<hr />

	<h2>Random Forest</h2>
	<h6>July 2020</h6><br/>
	<p>In this project, random forest algorithm is used to train the model. Feature importance is plotted for the analysis of the dataset.</p>
	<img src="images/Feature importance RF.png">
	<ul class="actions">
	<li><a href="files/Random Forest.pdf" target="_blank" class="button special icon fa-download">Report</a></li>
	</ul>
	<hr />

	<h2>Non-negative Matrix Factorization</h2>
	<h6>August 2020</h6><br/>
	<p>In this project, non-negative matrix factorization is used to train the recommendation algorithm.</p>
	<ul class="actions">
	<li><a href="files/Non-negative Matrix Factorization.pdf" target="_blank" class="button special icon fa-download">Report</a></li>
	</ul>
	<hr />

	<h2>Market Basket Analysis</h2>
	<h6>August 2020</h6><br/>
	<p>In this project, a market basket analysis is used as a recommendation algorithm. A priori algorithm is implemented in order to deduce the possible association rules from the dataset.</p>
	<ul class="actions">
	<li><a href="files/Market Basket Analysis.pdf" target="_blank" class="button special icon fa-download">Report</a></li>
	</ul>
